{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Model Building: Linear**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import (TimeSeriesSplit, GridSearchCV)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running notebook configuration\n"
     ]
    }
   ],
   "source": [
    "%run ../nb_config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'quandl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b1457f9f2faf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmle\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime_series\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmle_ts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\repos\\ai4forecast\\src\\load_data\\market_data.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mquandl\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mqua\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdotenv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dotenv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_dotenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'quandl'"
     ]
    }
   ],
   "source": [
    "from src.load_data import market_data\n",
    "from src.mle import time_series as mle_ts\n",
    "from src import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAU_TARGET = 5\n",
    "KFOLDS = 3\n",
    "RND_SEED = 123\n",
    "SPLIT_DT = '2019-12-31'\n",
    "DATA_END = '2020-06-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df = market_data.read_mkt_data().loc[:DATA_END, ['brent', 'wti']]\n",
    "target = mle_ts.get_targets(\n",
    "        y=comm_df.loc[:DATA_END, ['brent']], tau=TAU_TARGET\n",
    "    ).rename(columns={'brent':'target'})\n",
    "\n",
    "comm_df = comm_df.join(target, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['target_bin'] = (target['target']>=0).astype(int)\n",
    "target['target_w'] = target['target'].rolling(60, min_periods=1).apply(lambda x: (x[-1] - x.mean())/x.std(), raw=True).fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df['x_is_eom'] = comm_df.index.is_month_end.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_yr_feat = mle_ts.get_wave_features(comm_df.index.isocalendar().week, periods=[54], n_harmonics=1).values\n",
    "seas_yr_feat = pd.DataFrame(index=comm_df.index, data=seas_yr_feat, columns=['x_cos_yr', 'x_sin_yr'])\n",
    "comm_df[['x_cos_yr', 'x_sin_yr']] = seas_yr_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_wk_feat = mle_ts.get_wave_features(comm_df.index.dayofweek, periods=[5], n_harmonics=1).values\n",
    "seas_wk_feat = pd.DataFrame(index=comm_df.index, data=seas_wk_feat, columns=['x_cos_wk', 'x_sin_wk'])\n",
    "comm_df[['x_cos_wk', 'x_sin_wk']] = seas_wk_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_df[['brent_vs_wti']] = comm_df['brent'] - comm_df['wti']\n",
    "comm_df[['x_brent_vs_wti_zscored']] = mle_ts.z_score(x=comm_df[['brent_vs_wti']], win_size=60, min_periods=1, fillna=True) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = ['x_is_eom', 'x_cos_yr', 'x_sin_yr', 'x_cos_wk', 'x_sin_wk',\n",
    "                'x_brent_vs_wti_zscored', \n",
    "                'brent']\n",
    "\n",
    "X_train = comm_df.loc[:SPLIT_DT, raw_features]\n",
    "X_test = comm_df.loc[SPLIT_DT:, raw_features]\n",
    "y_train = target.loc[:SPLIT_DT, 'target_bin']\n",
    "y_test = target.loc[SPLIT_DT:, 'target_bin']\n",
    "w_train = target.loc[:SPLIT_DT, 'target_w']\n",
    "w_test = target.loc[SPLIT_DT:, 'target_w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=KFOLDS)\n",
    "sp_tscv  = tscv.split(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fte_macd = mle_ts.MACD(short_tau=3, long_tau=20, zscore_tau=90)\n",
    "fte_mom1 = mle_ts.Momentum(tau=10, zscore_tau=30, degree=1)\n",
    "fte_mom2 = mle_ts.Momentum(tau=10, zscore_tau=30, degree=2)\n",
    "fte_diff = mle_ts.Diff(tau=3, zscore_tau=30)\n",
    "fte_volat = mle_ts.Volatility(tau=10, zscore_tau=60)\n",
    "\n",
    "fte_ct = ColumnTransformer([\n",
    "        ('macd', fte_macd, ['brent']),\n",
    "        ('mom1', fte_mom1, ['brent']),\n",
    "        ('mom2', fte_mom2, ['brent']),\n",
    "        ('diff', fte_diff, ['brent']),\n",
    "        ('volat', fte_volat, ['brent']),\n",
    "    ],\n",
    "    remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [x[0] for x in fte_ct.transformers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = pd.DataFrame(fte_ct.fit_transform(X_train[['brent']])).corr('spearman')\n",
    "features_corr.index= feature_names\n",
    "features_corr.columns= feature_names\n",
    "\n",
    "sns.heatmap(features_corr, annot=True)\n",
    "plt.title('Multicollinearity: Spearman Corr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discr = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "model = LogisticRegression(fit_intercept=True, penalty='l2', random_state=RND_SEED)\n",
    "\n",
    "grid_hparams = {\n",
    "    'discr__n_bins': [3, 5, 10, 20],\n",
    "    'model__C': [0.0001, 0.001, 0.01, 0.1, 1.]\n",
    "               }\n",
    "\n",
    "pl = Pipeline([('fte', fte_ct), ('discr', discr), ('model', model)])\n",
    "\n",
    "pl_cv = GridSearchCV(pl, grid_hparams, scoring=('f1', 'roc_auc', 'accuracy'), cv=tscv, n_jobs=-1, refit='f1')\n",
    "pl_cv.fit(X_train[['brent']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cv_res = pd.DataFrame(pl_cv.cv_results_).sort_values(by='rank_test_f1')\n",
    "pl_cv_res.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cv_res.sort_values(by='rank_test_f1').plot.barh(x='params', y=['mean_test_f1', 'std_test_f1'], subplots=True, layout=(1,2), sharey=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cv_res.sort_values(by='rank_test_accuracy').iloc[:10].plot.barh(x='params', y=['mean_test_accuracy', 'std_test_accuracy'], subplots=True, layout=(1,2), sharey=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cv_res.loc[pl_cv_res['rank_test_f1']==1].filter(regex=r'(mean|std)_test_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best F1 model, achieves a good accuracy score, in addition, std deviations are the lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Champion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_cv.best_estimator_[-1].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(fit_intercept=True, penalty='l2', C=1, random_state=RND_SEED)\n",
    "\n",
    "base_mod = Pipeline([('fte', fte_ct), ('discr', discr), ('model', model)])\n",
    "\n",
    "base_mod.fit(X_train[['brent']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(fit_intercept=True, penalty='l2', C=0.01, random_state=RND_SEED)\n",
    "\n",
    "champ_mod = Pipeline([('fte', fte_ct), ('discr', discr), ('model', model)])\n",
    "\n",
    "champ_mod.fit(X_train[['brent']], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(X: pd.DataFrame, model, name='preds'):\n",
    "    return pd.Series(index=X.index, data=model.predict_proba(X)[:, 1], name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = get_preds(X_train[['brent']], champ_mod)\n",
    "p_test = get_preds(X_test[['brent']], champ_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_train>=0.5).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_test>=0.5).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, p_test>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, p_train>=0.5, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, p_test>=0.5, normalize='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, p_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train = pd.qcut(w_train, 5, labels=False)\n",
    "q_test = pd.qcut(w_test, 5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.concat([q_train, p_train, y_train], axis=1)\n",
    "y_test_df = pd.concat([q_test, p_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df['q_preds'] = pd.qcut(p_train, 5, labels=False)\n",
    "y_test_df['q_preds'] = pd.qcut(p_test, 5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df['target'] = target.loc[:SPLIT_DT, 'target']\n",
    "y_test_df['target'] = target.loc[SPLIT_DT:, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2 ,1, sharex=True, figsize=(16, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "y_train_df.groupby('q_preds')['target'].median().plot.bar(ax=ax)\n",
    "ax.set_ylabel(\"%\")\n",
    "ax.set_title(\"Model Post-Mortem Analysis: Train\")\n",
    "ax = axs[1]\n",
    "y_train_df.groupby('q_preds')['target_bin'].mean().plot.bar(ax=ax)\n",
    "ax.set_ylabel(\"event prop\")\n",
    "ax.set_xlabel(\"Predicted Probability Quantiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y_train_df['target'].plot.hist(label='train', density=True, alpha=0.5)\n",
    "y_test_df['target'].plot.hist(label='test', density=True, alpha=0.5, ax=ax)\n",
    "plt.title('target (raw)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mle_ts.run_adf_test(y_train_df[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df.groupby('target_bin')['target'].agg([np.size, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.groupby('target_bin')['target'].agg([np.size, np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y_train_df['preds'].plot.hist(label='train', density=True, alpha=0.5)\n",
    "y_test_df['preds'].plot.hist(label='test', density=True, alpha=0.5, ax=ax)\n",
    "plt.title('predicted probabilites')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, sharex=True, figsize=(16, 10))\n",
    "\n",
    "ax = axs[0]\n",
    "y_test_df.groupby('q_preds')['target'].median().plot.bar(ax=ax)\n",
    "ax.set_ylabel(\"target (%)\")\n",
    "ax.set_title(\"Model Post-Mortem Analysis: Test\")\n",
    "ax = axs[1]\n",
    "y_test_df.groupby('q_preds')['target_bin'].mean().plot.bar(ax=ax)\n",
    "ax.set_ylabel(\"event prop\")\n",
    "ax.set_xlabel(\"Predicted Probability Quantiles\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.loc[y_test_df['q_preds']==0, 'target_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df['q_preds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brent_test.loc[y_test_df['target_bin']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brent_test = comm_df.loc[SPLIT_DT:, 'brent']\n",
    "mask_short = y_test_df['q_preds']==0\n",
    "mask_long = y_test_df['q_preds']==4\n",
    "ax = brent_test.plot()\n",
    "brent_test.loc[mask_short].plot(ax=ax, style='v')\n",
    "brent_test.loc[mask_long].plot(ax=ax, style='^')\n",
    "\n",
    "for idx, row in y_test_df.loc[mask_short].iterrows():\n",
    "    if row['target_bin']<=0:\n",
    "        _color = 'green'\n",
    "    else:\n",
    "        _color = 'red'\n",
    "    ax.axvline(x=idx, linewidth=1, alpha=0.5, color=_color)\n",
    "    \n",
    "for idx, row in y_test_df.loc[mask_long].iterrows():\n",
    "    if row['target_bin']>0:\n",
    "        _color = 'green'\n",
    "    else:\n",
    "        _color = 'red'\n",
    "    ax.axvline(x=idx, linewidth=1, alpha=0.5, color=_color)\n",
    "    \n",
    "ax.set_ylabel('USD/bbl')\n",
    "ax.set_title('Brent Trades on Predicted Prob Quantiles = {0, 4}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names = [x[0] for x in champ_mod[0].transformers]\n",
    "features_imp = champ_mod[-1].coef_.reshape(-1)\n",
    "features_imp = pd.Series(index=feature_names, data=features_imp).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mod_feat_imp = pd.Series(index=feature_names , data=base_mod[-1].coef_.reshape(-1)).sort_values()\n",
    "base_mod_feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True)\n",
    "\n",
    "plt.suptitle('Feature Importance')\n",
    "ax = axs[0]\n",
    "ax.set_title('Champion Model (C=0.01)')\n",
    "features_imp.plot.barh(ax=ax)\n",
    "\n",
    "ax = axs[1]\n",
    "base_mod_feat_imp.plot.barh(ax=ax)\n",
    "ax.set_title('Base Model (C=1)')\n",
    "\n",
    "for ax in axs:\n",
    "    plt.xlabel('Coefficient Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
